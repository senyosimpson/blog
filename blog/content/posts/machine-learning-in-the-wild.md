---
title: "Machine learning in the wild"
draft: true
---

[comment]: # (https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/)
[comment]: # (https://medium.com/@nlauchande/review-notes-of-ml-platforms-uber-michelangelo-e133eb6031da)
[comment]: # (hidden technical debt of machine learning)

Machine learning promises to be transformational, providing much needed innovation across many industries, ranging from financial services to healthcare to agriculture. The resurgence of machine learning, due to the astonishing performance of deep learning in computer vision and natural language processing, has prompted industry to jump on the bandwagon and utilise machine learning in their businesses. In fact, entire startups are being built around machine learning alone, promising that their new found algorithms will vastly improve and outperform existing products and services.

While week-on-week, new state of the art algorithms are being published, using them in a production setting is non-trivial.
The additional complexity of using machine learning to power products cannot be understated. Surprising to new practitioners, most of this complexity has very little to do with the model itself but rather the infrastructure supporting it. In fact, a common trope is that the development of machine learning models comprises a small part of the puzzle. So what actually makes machine learning complex? Data cleaning and warehousing, data versioning, model versioning, distributed training (in the event you are training large models), reproducibility, concept drift, inference speed and optimizing the right thing to mention a *few*.

Fortunately, this makes for an extremely rewarding engineering experience. As engineers, we are drawn to technically challenging problems (or atleast, I'd hope so!). Machine learning in the wild does not fall short in any regard. It really is stimulating, might make you lose hair, destroy your laptop and move to the Motou but that is the best part! In this post, I illuminate some of the core challenges faced in walking the distance with machine learning.

## Data Quality

First things first, what is machine learning without data? The answer is nothing. Absolutely nothing. As the commmon saying goes garbage in, garbage out. Possibly the most important aspect of machine learning is the data used to train models. Without quality data, no amount of sophistication and creativity will help your machine learning model perform accurately. Whether you agree with [this tweet](https://twitter.com/jacobmenick/status/1260658763687538688) or not, it does provide an interesting angle on what a model is - it being a view of the data it was trained on. Data is the source of truth for your model, every phenomenon it is to learn is encompassed in that data. Given that stance, you'd be crazy to not ensure your model is trained on the highest quality data you can create or get your hands on. Unfortunately, ensuring data quality is difficult, expensive, requires plenty of human labour and there is no easy way around this problem. Rather than trying to circumvent this, it should be baked into the company/team strategy. Making the necessary provisions in capacity or budget will make this manageable. Ideally, ensuring data quality becomes just a nuisance instead of a blocking point to deploying machine learning models.

## Concept Drift

Real-life data is akin to a living organism. It is dynamic and changes over time, drifting further and further away from the data that came before it. This is called concept drift and it is a common challenge in machine learning. In its simplest form it is not difficult to deal with as it only requires training on the new batch of data. The complexity arises on an infrastructural level. To handle this effectively, it requires models to be continuously retrained as their performance starts detoriating in production. Setting up the correct infrastructure to facilitate easy training to deployment and monitoring in production can be difficult depending on the velocity at which this needs to happen. In [this blog post](https://netflixtechblog.com/system-architectures-for-personalization-and-recommendation-e081aa94b5d8) by Netflix, they discuss their system architecture for recommdentations. Interesting to note is their separation of offline, online and nearline computation. Offline is the most common paradigm in machine learning today where data is stored and models are trained on the new data. However, they reached limitations with this approach as often it took time between updates to the models and thus they would become out of date. They solve this problem using online computation which reacts to the latest changes in the data in real-time. Nearline computation is a hybrid of these two approaches. Considering Netflix's scale, most of us would not need such comprehensive architectures to run machine learning in production but it certainly highlights the complexity that can arise.

To drive concept drift home, we walk through an example. Keeping with our theme of Netflix, imagine you worked there and trained a recommendation model in January. At this period of time, life was good and relaxed. A majority of the customers were watching comedy shows. The model was able to learn this and its performance was admirable and subsequently deployed into production. It is now June and you realise the model is underperforming. The world is going through a pandemic and in response, people have stopped watching comedy and are watching plenty of thrillers and horrors. Evidently, the behaviour of the people has changed and thus the dataset used to train the model in January is outdated. To bring the model up to date, you train it on the latest data and as expected, your magic algorithm is performing well again, hooray!

## Versioning

Versioning is an essential part of software engineering. Git has largely solved this problem for traditional software development. In machine learning, we not only have to version our code but also the parameters of our model and the data that was used to train the model.

Data versioning is a new challenge that machine learning brings to the table. As discussed earlier, data is the source of truth for a model. When models are trained on different data, we naturally expect differences in their performance. Without keeping track of which data a model is trained on, we cannot make any significant claims on its performance relative to another model. Alongside that, without knowing which dataset a model was evaluated on, we cannot fairly compare competing models. Finally, we cannot reproduce experiments if we do not version our data. Reproducibility is a growing concern in the machien learning community and rightfully so, therefore ensuring we create the best environment for it is important. From this it is clear that data provenance is of the utmost importance in machine learning efforts. At this current time, there is no industry standard for data versioning. There are many options available in the market. A few of them include [dvc](https://dvc.org/), [dolt](https://www.liquidata.co/) and [pachyderm](https://www.pachyderm.com/data-lineage/). They do not all fall within the same use cases but there is plenty of overlap between them.

A simple scenario in which poor data versioning can play against you is during the experimentation phase. You decide to embark on a journey to create an object detection system. You train a model with dataset A. You decide to change the data slightly and train on a model on this data, dataset B. You repeat this two more times, making dataset C and D. After all these experiments, you find the models trained on dataset A and C perform the best. Unfortunately, you never logged the differences between those datasets and only posses the data with the latest changes (dataset D). It is now impossible for her to reproduce her best performing model, a true tragedy. Alongside this, she cannot understand why datasets A and C lead to the best models, reducing her understanding and confidence in the model performance. This highlights the importance of data versioning and why it is so important to the machine learning process.

## Experimentation Infrastructure/Platforms

Experimentation infrastructure/platforms refer to the necessary infrastructure/platforms needed to use machine learning as effectively as possible. It is not necessary in the beginning of the machine learning journey but as a company begins to scale up their machine learning efforts, it becomes critical. Thousands of experiments need to be run and evaluated and having the correct infrastructure and tools make the iteration speed quick and allow models to actually make it into production.

Let's walk through an example to highlight its importance. You've decided that you need to create and train a new model for fraud detection. You whip out your trusty jupyter notebook and set off on an adventure of a lifetime. On completion of your model and dataset, you proceeds to train the model on a virtual server the company provides on their prefered cloud provider. The virtual server is not configurated, has no fault tolerance and requires many manual steps (ssh into it, install all dependencies, monitoring it, etc). Naturally, there are many points of failure here and just general headaches, slowing your development time. The company realises this is inefficient and moves their training and evaluation to [Kubeflow](https://www.kubeflow.org/). From all those manual headaches, all you need to do execute jobs on Kubeflow is build a docker container and execute it with a simple script. Now you have instant monitoring of its progress, easily view the outputs, training and validation loss and view the results on a user-friendly dashboard. Clearly this has improved the iteration speed, removed the need to fully understand infrastructure and given the necessary amount of visibility. By using the correct platform, the time taken between iterations has decreased substantially.

Eventually, there is an upfront that must be paid in scaling out machine learning efforts by providing the necessary infrastructure and platforms. Data scientists and machine learning engineers need to be empowered to do their work effectively and this is one step in that direction. Alongside this, it allows them to add more value by being able to improve their models in a shorter period of time.


## Optimizing the right thing

In many product offerings, the core goal of machine learning is to improve the *customer* experience. In a music company such as Spotify, it could be utilised to improve their song recommendations, personalising them to your music taste. In a medical imaging company, it could help doctors make more accurate diagnosis or provide the diagnosis itself. Metrics provide an objective way to rank the performance of models and ensure you have the latest and greatest model in production. Unfortunately, a common pitfall is optimizing the wrong metric and by wrong metric, I mean one that does not translate to an improvement in the *customer* experience. A simple question to ask is, what does a 10% improvement of this metric mean for the customer? It is often quite simple to analyse your model against standard metrics in that line of work, however, they do not always translate to an actual improvement for the purpose they serve. A simple case to illuminate this is in medical diagnosis. Imagine you are the patient and this revolutionary AI is used to diagnose you. If the model predicts that you have a disease and you do not, the total harm done is minimal. It may gotten it wrong but at least you will survive and hopefully live for many more exciting years to come! Contrary to that, imagine the model predicts that you do not have a disease but you do. Now the doctor lets you off into the world to fend for yourself, with no mediciation and treatment. This is a particularly harmful situation and may lead to severe consequences. Now imagine you are responsible for creating the model that performs this task and your chosen metric is accuracy. Accuracy measures the total number of correct predictions out of total predictions. Your new model is 5% better than your old model and so you release it into production, happy days! Unfortunately, that metric does not communicate the most important value to you, how often your model predicts an individual does not have a disease when they actually do! The appropriate metric is actually recall. In plain English and relevant to this context, perfect recall means the model successfully predicts every case of an individual having a disease, however it may make mistakes and predict people have the disease when they do not.

The above use case is simple to reason about. If only it was always this easy! In the majority of cases, metrics will have to be designed with the aim of an improvement in the metrics translating to an improvement in the customer experience. This [talk]() by Jade Abbott walks through an example of this.

The main takeaway is that metrics should be carefully designed and give an indication of the model's impact on the customer. Additionally, it allows the rest of the business to understand the value of the work you are doing. Then they will also celebrate when your model improves by 0.01%!

Machine learning in the wild is difficult! This should not discourage us by any means. While difficult, it is extremely rewarding and if you're the kind of engineer I hope you are, it is exciting! With all difficult things comes the joy of working on technically challenging problems.